{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "import numpy as np\n",
    "\n",
    "def solve_cgains(mat, ref=0, fix_off=True):\n",
    "    if mat.shape[0] == 1:\n",
    "        # If we only have one antenna, then this whole thing can be bypassed.\n",
    "        return np.ones([1], dtype=mat.dtype)\n",
    "\n",
    "    eig_vals, eig_vecs = np.linalg.eig(mat)\n",
    "    soln_idx = eig_vals.real.argmax()\n",
    "    gain_soln = (eig_vecs[:, soln_idx] * np.sqrt(eig_vals[soln_idx].real)).squeeze()\n",
    "\n",
    "    if np.isfinite(gain_soln[ref]):\n",
    "        # Apply reference antenna phase to the solutions\n",
    "        gain_soln *= np.exp(-1j*np.angle(gain_soln[ref]))\n",
    "\n",
    "        # Normalize to account for the fact the autos have been removed -- more\n",
    "        # specifically, the real components (since the imag should be zero).\n",
    "        if fix_off:\n",
    "            gain_soln *= np.sqrt(2 * mat.size / ((2 * mat.size) - gain_soln.size))\n",
    "\n",
    "        # Avoid numerical precision issues, explicitly zero out phaes for refant\n",
    "        gain_soln.imag[ref] = 0\n",
    "\n",
    "    return gain_soln"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "n_trials = 100\n",
    "score_a = np.zeros(n_trials)\n",
    "score_b = np.zeros(n_trials)\n",
    "score_c = np.zeros(n_trials)\n",
    "score_d = np.zeros(n_trials)\n",
    "scale_fac = 0.2\n",
    "gain_vec = np.ones(8, dtype='c16') * scale_fac\n",
    "#gain_vec[-1] = 0.5\n",
    "corr_matrix1 = np.ones((8, 8), dtype='c16')\n",
    "corr_matrix2 = np.zeros((8, 8), dtype='c16')\n",
    "for trial in range(n_trials):\n",
    "    for idx in range(8):\n",
    "        for jdx in range(8):\n",
    "            if jdx < idx:\n",
    "                corr_matrix1[idx, jdx] = np.conj(corr_matrix1[jdx, idx])\n",
    "                corr_matrix2[idx, jdx] = np.conj(corr_matrix2[jdx, idx])\n",
    "            elif jdx != idx:\n",
    "                spec = (gain_vec[idx] * gain_vec[jdx]) + np.random.randn(32768).view('c16')\n",
    "                corr_matrix1[idx, jdx] = np.mean(spec/abs(spec))\n",
    "                corr_matrix2[idx, jdx] = np.median(spec.real) + np.median(spec.imag)*1j\n",
    "    soln1 = solve_cgains(corr_matrix1, fix_off=False)\n",
    "    soln2 = solve_cgains(corr_matrix2, fix_off=True)\n",
    "    score_a[trial] = np.mean(np.exp(1j*np.angle(soln1))*gain_vec).real**2.0\n",
    "    score_b[trial] = np.mean(np.exp(1j*np.angle(soln2))*gain_vec).real**2.0\n",
    "    score_c[trial] = abs(np.sum(soln1))/np.sum(abs(soln1))\n",
    "    score_d[trial] = abs(np.sum(soln2))/np.sum(abs(soln2))\n",
    "\n",
    "print(np.mean(score_a)/(scale_fac**2), np.mean(score_b)/(scale_fac**2), np.mean(score_c), np.mean(score_d))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9895310904700279 0.9879683725964372 0.9974276371035206 0.9969355590672664\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "print(abs(soln1/soln2))\n",
    "print(abs(soln2/gain_vec))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.88063355 2.01884891 2.11246521 1.91154418 1.88408921 1.81125978\n",
      " 1.96490053 2.01590965]\n",
      "[0.98807236 0.92707591 0.86392045 1.01322933 1.14527806 1.04562653\n",
      " 1.03195892 0.88633924]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data_arr = ones((768, 2, 32768), dtype='<f4')\n",
    "cross_idx = arange(96, 768)\n",
    "auto1_idx = arange(96, 768) % 96\n",
    "auto2_idx = (arange(96, 768) // 32) % 96\n",
    "auto_sb_idx = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "%timeit normalize_data(data_arr.view('<c8'), cross_idx, auto1_idx, auto2_idx, auto_sb_idx)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15.6 ms ± 432 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "dummy_data = np.ones((512 * 6, 16384 * 2), dtype='<f4')\n",
    "dummy_data[:, ::2] = 0\n",
    "dummy_phase = np.ones((512 * 6), dtype='<c8') * (0.6 + 0.8j)\n",
    "\n",
    "def complex_nan_to_num(arr):\n",
    "    arr[np.isnan(arr)] == 0\n",
    "    return arr\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "%%timeit\n",
    "new_dummy = np.zeros((16384, 8, 8), dtype='c16')\n",
    "for idx in range(64):\n",
    "    if (idx % 8) != (idx // 8):\n",
    "        baseline_data = dummy_data[idx<<2]\n",
    "        complex_data = baseline_data[0::2] + 1j * baseline_data[1::2]\n",
    "        new_dummy[:, idx % 8, idx // 8] = complex_data\n",
    "\n",
    "np.mean(np.divide(new_dummy, abs(new_dummy), where=(new_dummy != 0)), axis=0)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "36 ms ± 673 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%%timeit\n",
    "for idx in range(len(dummy_data)):\n",
    "    # Extract complex correlator data\n",
    "    baseline_data = dummy_data[idx]\n",
    "    complex_data = baseline_data[0::2] + 1j * baseline_data[1::2]\n",
    "\n",
    "    # Apply phases\n",
    "    complex_data = complex_data * dummy_phase[idx]\n",
    "\n",
    "    # Reformat to original format and store\n",
    "    baseline_data = np.vstack((complex_data.real,complex_data.imag)).flatten(order='F')\n",
    "    dummy_data[idx] = baseline_data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "666 ms ± 5.41 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "%%timeit\n",
    "for idx in range(len(dummy_data)):\n",
    "    # Extract complex correlator data\n",
    "    baseline_data = dummy_data[idx].view('<c8')\n",
    "    baseline_data *= dummy_phase[idx]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "85.2 ms ± 437 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "np.abs(dummy_data[0, 0:2].view('c8'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.0000023], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "import numpy as np\n",
    "\n",
    "def gain_solve(vis_data, ant1arr, ant2arr, vis_model=None, vis_noise=None, ref_ant=None, tol_spec=1e-5):\n",
    "    complex_dtype = \"%sc%i\" % (vis_data.dtype.byteorder, vis_data.dtype.itemsize)\n",
    "    float_dtype = \"%sf%i\" % (vis_data.dtype.byteorder, vis_data.dtype.itemsize // 2)\n",
    "\n",
    "    # This is some basic import stuff\n",
    "    ref_ant = 0\n",
    "\n",
    "    # Basic data screening, make sure that everything looks okay and that\n",
    "    # we have the relevant metadata on array shapes.\n",
    "\n",
    "    # Enforce the existence of a model\n",
    "    if vis_model is None:\n",
    "        vis_model = np.ones_like(vis_data)\n",
    "    elif (True if (not isinstance(vis_model, np.ndarray)) else (vis_model.size == 1)):\n",
    "        vis_model = np.ones_like(vis_data) * vis_model\n",
    "    elif vis_model.shape != vis_data.shape:\n",
    "        raise ValueError(\"vis_model must be the same shape as vis_data.\")\n",
    "\n",
    "    # Enforce the existence of a data weights\n",
    "    if vis_noise is None:\n",
    "        vis_noise = np.ones_like(vis_data)\n",
    "    elif (True if (not isinstance(vis_noise, np.ndarray)) else (vis_noise.size == 1)):\n",
    "        vis_noise = np.ones_like(vis_data) * vis_noise\n",
    "    elif vis_noise.shape != vis_data.shape:\n",
    "        raise ValueError(\"vis_noise must be the same shape as vis_data.\")\n",
    "\n",
    "\n",
    "    data_mask = np.isfinite(vis_model) & np.isfinite(vis_noise) & np.isfinite(vis_data)\n",
    "    if not np.all(data_mask):\n",
    "        ant1arr = ant1arr[data_mask]\n",
    "        ant2arr = ant2arr[data_mask]\n",
    "        vis_data = vis_data[data_mask]\n",
    "        vis_noise = vis_noise[data_mask]\n",
    "\n",
    "    data_weight = (1. / vis_noise)\n",
    "\n",
    "    # Prep data for LS processing, get some basic values\n",
    "    n_ants = len(set(ant1arr).union(set(ant2arr)))\n",
    "    n_base = vis_data.size\n",
    "\n",
    "    # Build up the coordinate list for plugging things in\n",
    "    common_coords = np.empty(4 * n_base, dtype=int)\n",
    "    base_idx = np.arange(n_base)\n",
    "    common_coords[0::4] = base_idx + (n_base * ((2 * ant1arr) - (ant1arr > ref_ant)))\n",
    "    common_coords[2::4] = base_idx + (n_base * ((2 * ant2arr) - (ant2arr > ref_ant)))\n",
    "    common_coords[1::2] = common_coords[::2] + n_base\n",
    "    base_idx = np.repeat(base_idx, 4)\n",
    "\n",
    "    pos_coords = np.empty(4 * n_base, dtype=int)\n",
    "    pos_coords[0::4] = (2 * ant2arr)\n",
    "    pos_coords[2::4] = (2 * ant1arr)\n",
    "    pos_coords[1::2] = pos_coords[::2] + 1\n",
    "\n",
    "    neg_coords = np.empty(4 * n_base, dtype=int)\n",
    "    neg_coords[1::4] = (2 * ant2arr)\n",
    "    neg_coords[3::4] = (2 * ant1arr)\n",
    "    neg_coords[0::2] = neg_coords[1::2] + 1\n",
    "\n",
    "    #sign_vals = np.tile([-1, 1, 1, -1], dtype=float_dtype), n_base)\n",
    "    sign_vals = np.ones(4 * n_base, dtype=float_dtype)\n",
    "    sign_vals[0::4] = -1.\n",
    "    sign_vals[3::4] = -1.\n",
    "\n",
    "    common_mask = np.ones(4 * n_base, dtype=bool)\n",
    "    common_mask[1::4] = ant1arr != ref_ant\n",
    "    common_mask[3::4] = ant2arr != ref_ant\n",
    "\n",
    "    common_coords = common_coords[common_mask]\n",
    "    pos_coords = pos_coords[common_mask]\n",
    "    neg_coords = neg_coords[common_mask]\n",
    "    sign_vals = sign_vals[common_mask]\n",
    "    base_idx = base_idx[common_mask]\n",
    "\n",
    "    # toTest is the change in solution from value to value.\n",
    "    tol_test = 1\n",
    "    cycle=0\n",
    "\n",
    "    # cycleFinLim is the number of iterations to try before bailing. nParams^2\n",
    "    # appeared to give the best dynamic results (i.e. if a solution is possible,\n",
    "    # Monte Carlo tests showed that it always appeared in this number of cycles).\n",
    "    cycle_lim = 64 if (n_ants < 5) else (((2 * n_ants) - 1) ** 2)\n",
    "\n",
    "    # gain_guess provides a first guess based on the baselines of the refAnt. This\n",
    "    # step seems to cut convergence time in half. Needs to be split into separate\n",
    "    # real and imag components for the solver, though.\n",
    "    # TODO: Put guess code here\n",
    "    ant_guess = np.ones(n_ants, dtype=complex_dtype)\n",
    "\n",
    "    guess_mask = np.ones(n_ants * 2, dtype=bool)\n",
    "    guess_mask[(2 * ref_ant) + 1] = False\n",
    "\n",
    "    del_guess = np.zeros(n_ants, dtype=complex_dtype)\n",
    "    tot_mask = np.zeros(((2 * n_ants) - 1) * n_base, dtype=complex_dtype)\n",
    "\n",
    "    # Here is the solver loop.\n",
    "    # Complete either by hitting cycle limit or hitting tolerance target\n",
    "    last_val = 1e300\n",
    "    tol_test = 1\n",
    "    damp_fac = 1\n",
    "    while (cycle < cycle_lim):\n",
    "\n",
    "        # Create some gain correction factors, which will be used later\n",
    "        # to determine the data residuals\n",
    "        gain_app = ant_guess[ant1arr] * np.conj(ant_guess[ant2arr])\n",
    "        cycle += 1\n",
    "\n",
    "        # Create a \"generic\" mask based of the first-order Taylor expansion\n",
    "        # of the gains.    \n",
    "        tot_mask.real[common_coords] = ant_guess.view(float_dtype)[pos_coords]\n",
    "        tot_mask.imag[common_coords] = ant_guess.view(float_dtype)[neg_coords] * sign_vals\n",
    "        tot_mask[common_coords] *= (data_weight * vis_model)[base_idx]\n",
    "\n",
    "        # Calculate the true x-values for each table entry, corrected for noise\n",
    "        x_matrix = tot_mask.reshape((2 * n_ants) - 1, n_base).view(float_dtype)\n",
    "\n",
    "        # Calculate the true residuals, corrected for noise, convert to floats\n",
    "        # so that we can evaluate the matrix more easily\n",
    "        y_vec = ((vis_data - (vis_model * gain_app)) * data_weight).view(float_dtype)\n",
    "        curr_val = np.sum(y_vec**2)\n",
    "\n",
    "        if (np.abs(last_val - curr_val) < (curr_val * tol_spec)) and (\n",
    "            damp_fac > (1. - (1 / (2 * n_ants - 1)))\n",
    "        ):\n",
    "            break\n",
    "        last_val = curr_val\n",
    "\n",
    "        alpha_matrix = x_matrix @ x_matrix.T\n",
    "        beta_matrix = x_matrix @ y_vec\n",
    "        del_guess.view(float_dtype)[guess_mask] = np.linalg.solve(alpha_matrix, beta_matrix)\n",
    "\n",
    "        # Add new deltas to solutions, but dampen it in the case of large changes to\n",
    "        # prevent positive feedback loops. The formula below is based on how large\n",
    "        # the deltas need to be in order for second-order effects to create such\n",
    "        # loops. Increases the number of cycles requires by convergence by up to 50%,\n",
    "        # but greatly enhances stability.\n",
    "        damp_fac = (1. + ((np.abs(del_guess) / np.abs(ant_guess)).sum()) / n_ants) ** -1\n",
    "        ant_guess = ant_guess + (del_guess * damp_fac)\n",
    "\n",
    "        # Prevent a degenerate case where the phase of the refant becomes 180\n",
    "        # instead of zero (i.e. a negative, real number for the gains soln).\n",
    "        if  ant_guess[ref_ant].real < 0:\n",
    "            ant_guess *= -1\n",
    "\n",
    "    # Finally, handle the results\n",
    "\n",
    "    # Are there any NaNs, Infs or zeros in the gains soln?\n",
    "    err_check = not (np.all(ant_guess) and np.all(np.isfinite(ant_guess)))\n",
    "\n",
    "    # If we reached the cycle lim or there was an error in the check above,\n",
    "    # mark solutions as bad.\n",
    "    if (cycle == cycle_lim) or err_check:\n",
    "        gain_table = np.zeros(n_ants * 2)\n",
    "        gain_covar = np.zeros((n_ants * 2, n_ants * 2))\n",
    "        gain_errs = np.zeros(n_ants * 2)\n",
    "    else:\n",
    "        gain_table = ant_guess\n",
    "        covar_matrix = np.linalg.inv(alpha_matrix)\n",
    "        rchi2_val =  np.dot(y_vec, y_vec) / ((2 * len(vis_data)) - ((2 * n_ants) - 1))\n",
    "        gain_var = np.zeros(2 * n_ants, dtype=float_dtype)\n",
    "        gain_var[guess_mask] = np.diag(covar_matrix) * rchi2_val\n",
    "        gain_var[2 * ref_ant] *= 2\n",
    "        gain_errs = np.sqrt(gain_var.reshape(-1, 2).sum(-1) * 0.5)\n",
    "\n",
    "    return gain_table, gain_errs, cycle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "def test_loop_gains():\n",
    "    bad_count = 0\n",
    "    real_bad_count = 0\n",
    "    total_count = 16384\n",
    "    cycle_count = 0\n",
    "    ant1arr = np.array([idx for idx in range(8) for jdx in range(idx + 1, 8)])\n",
    "    ant2arr = np.array([jdx for idx in range(8) for jdx in range(idx + 1, 8)])\n",
    "    vis_model = np.ones(28)\n",
    "    vis_noise = np.ones(28)\n",
    "    err_check = 0.0\n",
    "    for idx in range(total_count):\n",
    "        vis_data = 0.1 * (0.5 ** 2.0) * (np.random.randn(28) + (1j * np.random.randn(28))) + 1.0\n",
    "        gain_table, gain_errs, cycle = gain_solve(vis_data, ant1arr, ant2arr, vis_model=vis_model, vis_noise=vis_noise)\n",
    "        cycle_count += cycle\n",
    "        #gain_grade = np.mean(np.abs(gain_table - 1)**2)**0.5\n",
    "        #if gain_grade > 1e3:\n",
    "        #    real_bad_count += 1\n",
    "        #if gain_grade > 1:\n",
    "        #    bad_count += 1\n",
    "        #err_check += np.sum(np.abs((gain_table - 1.) / gain_errs)**2.) / 16.\n",
    "        \n",
    "    #print(cycle_count / total_count, 100*bad_count / total_count, 100*real_bad_count / total_count)\n",
    "    #print(err_check / total_count)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "%load_ext line_profiler"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "%lprun -f gain_solve test_loop_gains()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 10.4707 s\n",
      "File: /var/folders/6k/9m18n_s947n5ts95gb8v5v180000gn/T/ipykernel_24591/3397059766.py\n",
      "Function: gain_solve at line 3\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     3                                           def gain_solve(vis_data, ant1arr, ant2arr, vis_model=None, vis_noise=None, ref_ant=None, tol_spec=1e-5):\n",
      "     4     16384      48894.0      3.0      0.5      complex_dtype = \"%sc%i\" % (vis_data.dtype.byteorder, vis_data.dtype.itemsize)\n",
      "     5     16384      28610.0      1.7      0.3      float_dtype = \"%sf%i\" % (vis_data.dtype.byteorder, vis_data.dtype.itemsize // 2)\n",
      "     6                                           \n",
      "     7                                               # This is some basic import stuff\n",
      "     8     16384      15595.0      1.0      0.1      ref_ant = 0\n",
      "     9                                           \n",
      "    10                                               # Basic data screening, make sure that everything looks okay and that\n",
      "    11                                               # we have the relevant metadata on array shapes.\n",
      "    12                                           \n",
      "    13                                               # Enforce the existence of a model\n",
      "    14     16384      16975.0      1.0      0.2      if vis_model is None:\n",
      "    15                                                   vis_model = np.ones_like(vis_data)\n",
      "    16     16384      26803.0      1.6      0.3      elif (True if (not isinstance(vis_model, np.ndarray)) else (vis_model.size == 1)):\n",
      "    17                                                   vis_model = np.ones_like(vis_data) * vis_model\n",
      "    18     16384      21958.0      1.3      0.2      elif vis_model.shape != vis_data.shape:\n",
      "    19                                                   raise ValueError(\"vis_model must be the same shape as vis_data.\")\n",
      "    20                                           \n",
      "    21                                               # Enforce the existence of a data weights\n",
      "    22     16384      15860.0      1.0      0.2      if vis_noise is None:\n",
      "    23                                                   vis_noise = np.ones_like(vis_data)\n",
      "    24     16384      19729.0      1.2      0.2      elif (True if (not isinstance(vis_noise, np.ndarray)) else (vis_noise.size == 1)):\n",
      "    25                                                   vis_noise = np.ones_like(vis_data) * vis_noise\n",
      "    26     16384      18388.0      1.1      0.2      elif vis_noise.shape != vis_data.shape:\n",
      "    27                                                   raise ValueError(\"vis_noise must be the same shape as vis_data.\")\n",
      "    28                                           \n",
      "    29                                           \n",
      "    30     16384     107088.0      6.5      1.0      data_mask = np.isfinite(vis_model) & np.isfinite(vis_noise) & np.isfinite(vis_data)\n",
      "    31     16384     201896.0     12.3      1.9      if not np.all(data_mask):\n",
      "    32                                                   ant1arr = ant1arr[data_mask]\n",
      "    33                                                   ant2arr = ant2arr[data_mask]\n",
      "    34                                                   vis_data = vis_data[data_mask]\n",
      "    35                                                   vis_noise = vis_noise[data_mask]\n",
      "    36                                           \n",
      "    37     16384      56497.0      3.4      0.5      data_weight = (1. / vis_noise)\n",
      "    38                                           \n",
      "    39                                               # Prep data for LS processing, get some basic values\n",
      "    40     16384     179252.0     10.9      1.7      n_ants = len(set(ant1arr).union(set(ant2arr)))\n",
      "    41     16384      19344.0      1.2      0.2      n_base = vis_data.size\n",
      "    42                                           \n",
      "    43                                               # Build up the coordinate list for plugging things in\n",
      "    44     16384      46660.0      2.8      0.4      common_coords = np.empty(4 * n_base, dtype=int)\n",
      "    45     16384      50395.0      3.1      0.5      base_idx = np.arange(n_base)\n",
      "    46     16384     151155.0      9.2      1.4      common_coords[0::4] = base_idx + (n_base * ((2 * ant1arr) - (ant1arr > ref_ant)))\n",
      "    47     16384      86984.0      5.3      0.8      common_coords[2::4] = base_idx + (n_base * ((2 * ant2arr) - (ant2arr > ref_ant)))\n",
      "    48     16384      50847.0      3.1      0.5      common_coords[1::2] = common_coords[::2] + n_base\n",
      "    49     16384     134281.0      8.2      1.3      base_idx = np.repeat(base_idx, 4)\n",
      "    50                                           \n",
      "    51     16384      41143.0      2.5      0.4      pos_coords = np.empty(4 * n_base, dtype=int)\n",
      "    52     16384      51882.0      3.2      0.5      pos_coords[0::4] = (2 * ant2arr)\n",
      "    53     16384      36409.0      2.2      0.3      pos_coords[2::4] = (2 * ant1arr)\n",
      "    54     16384      44525.0      2.7      0.4      pos_coords[1::2] = pos_coords[::2] + 1\n",
      "    55                                           \n",
      "    56     16384      35335.0      2.2      0.3      neg_coords = np.empty(4 * n_base, dtype=int)\n",
      "    57     16384      39662.0      2.4      0.4      neg_coords[1::4] = (2 * ant2arr)\n",
      "    58     16384      35373.0      2.2      0.3      neg_coords[3::4] = (2 * ant1arr)\n",
      "    59     16384      42677.0      2.6      0.4      neg_coords[0::2] = neg_coords[1::2] + 1\n",
      "    60                                           \n",
      "    61                                               #sign_vals = np.tile([-1, 1, 1, -1], dtype=float_dtype), n_base)\n",
      "    62     16384     146963.0      9.0      1.4      sign_vals = np.ones(4 * n_base, dtype=float_dtype)\n",
      "    63     16384      33937.0      2.1      0.3      sign_vals[0::4] = -1.\n",
      "    64     16384      23182.0      1.4      0.2      sign_vals[3::4] = -1.\n",
      "    65                                           \n",
      "    66     16384     104630.0      6.4      1.0      common_mask = np.ones(4 * n_base, dtype=bool)\n",
      "    67     16384      59645.0      3.6      0.6      common_mask[1::4] = ant1arr != ref_ant\n",
      "    68     16384      38627.0      2.4      0.4      common_mask[3::4] = ant2arr != ref_ant\n",
      "    69                                           \n",
      "    70     16384      46088.0      2.8      0.4      common_coords = common_coords[common_mask]\n",
      "    71     16384      27116.0      1.7      0.3      pos_coords = pos_coords[common_mask]\n",
      "    72     16384      25806.0      1.6      0.2      neg_coords = neg_coords[common_mask]\n",
      "    73     16384      25375.0      1.5      0.2      sign_vals = sign_vals[common_mask]\n",
      "    74     16384      24889.0      1.5      0.2      base_idx = base_idx[common_mask]\n",
      "    75                                           \n",
      "    76                                               # toTest is the change in solution from value to value.\n",
      "    77     16384      17018.0      1.0      0.2      tol_test = 1\n",
      "    78     16384      16068.0      1.0      0.2      cycle=0\n",
      "    79                                           \n",
      "    80                                               # cycleFinLim is the number of iterations to try before bailing. nParams^2\n",
      "    81                                               # appeared to give the best dynamic results (i.e. if a solution is possible,\n",
      "    82                                               # Monte Carlo tests showed that it always appeared in this number of cycles).\n",
      "    83     16384      30121.0      1.8      0.3      cycle_lim = 64 if (n_ants < 5) else (((2 * n_ants) - 1) ** 2)\n",
      "    84                                           \n",
      "    85                                               # gain_guess provides a first guess based on the baselines of the refAnt. This\n",
      "    86                                               # step seems to cut convergence time in half. Needs to be split into separate\n",
      "    87                                               # real and imag components for the solver, though.\n",
      "    88                                               # TODO: Put guess code here\n",
      "    89     16384     117970.0      7.2      1.1      ant_guess = np.ones(n_ants, dtype=complex_dtype)\n",
      "    90                                           \n",
      "    91     16384      95832.0      5.8      0.9      guess_mask = np.ones(n_ants * 2, dtype=bool)\n",
      "    92     16384      27746.0      1.7      0.3      guess_mask[(2 * ref_ant) + 1] = False\n",
      "    93                                           \n",
      "    94     16384      38483.0      2.3      0.4      del_guess = np.zeros(n_ants, dtype=complex_dtype)\n",
      "    95     16384      49300.0      3.0      0.5      tot_mask = np.zeros(((2 * n_ants) - 1) * n_base, dtype=complex_dtype)\n",
      "    96                                           \n",
      "    97                                               # Here is the solver loop.\n",
      "    98                                               # Complete either by hitting cycle limit or hitting tolerance target\n",
      "    99     16384      17200.0      1.0      0.2      last_val = 1e300\n",
      "   100     16384      16801.0      1.0      0.2      tol_test = 1\n",
      "   101     16384      16133.0      1.0      0.2      damp_fac = 1\n",
      "   102     65525      72914.0      1.1      0.7      while (cycle < cycle_lim):\n",
      "   103                                           \n",
      "   104                                                   # Create some gain correction factors, which will be used later\n",
      "   105                                                   # to determine the data residuals\n",
      "   106     65525     275115.0      4.2      2.6          gain_app = ant_guess[ant1arr] * np.conj(ant_guess[ant2arr])\n",
      "   107     65525      76704.0      1.2      0.7          cycle += 1\n",
      "   108                                           \n",
      "   109                                                   # Create a \"generic\" mask based of the first-order Taylor expansion\n",
      "   110                                                   # of the gains.    \n",
      "   111     65525     212956.0      3.2      2.0          tot_mask.real[common_coords] = ant_guess.view(float_dtype)[pos_coords]\n",
      "   112     65525     205988.0      3.1      2.0          tot_mask.imag[common_coords] = ant_guess.view(float_dtype)[neg_coords] * sign_vals\n",
      "   113     65525     428759.0      6.5      4.1          tot_mask[common_coords] *= (data_weight * vis_model)[base_idx]\n",
      "   114                                           \n",
      "   115                                                   # Calculate the true x-values for each table entry, corrected for noise\n",
      "   116     65525     203681.0      3.1      1.9          x_matrix = tot_mask.reshape((2 * n_ants) - 1, n_base).view(float_dtype)\n",
      "   117                                           \n",
      "   118                                                   # Calculate the true residuals, corrected for noise, convert to floats\n",
      "   119                                                   # so that we can evaluate the matrix more easily\n",
      "   120     65525     300180.0      4.6      2.9          y_vec = ((vis_data - (vis_model * gain_app)) * data_weight).view(float_dtype)\n",
      "   121     65525    1031507.0     15.7      9.9          curr_val = np.sum(y_vec**2)\n",
      "   122                                           \n",
      "   123     81909     325396.0      4.0      3.1          if (np.abs(last_val - curr_val) < (curr_val * tol_spec)) and (\n",
      "   124     16384      29231.0      1.8      0.3              damp_fac > (1. - (1 / (2 * n_ants - 1)))\n",
      "   125                                                   ):\n",
      "   126     16384      17321.0      1.1      0.2              break\n",
      "   127     49141      55533.0      1.1      0.5          last_val = curr_val\n",
      "   128                                           \n",
      "   129     49141     412086.0      8.4      3.9          alpha_matrix = x_matrix @ x_matrix.T\n",
      "   130     49141     177636.0      3.6      1.7          beta_matrix = x_matrix @ y_vec\n",
      "   131     49141    1544880.0     31.4     14.8          del_guess.view(float_dtype)[guess_mask] = np.linalg.solve(alpha_matrix, beta_matrix)\n",
      "   132                                           \n",
      "   133                                                   # Add new deltas to solutions, but dampen it in the case of large changes to\n",
      "   134                                                   # prevent positive feedback loops. The formula below is based on how large\n",
      "   135                                                   # the deltas need to be in order for second-order effects to create such\n",
      "   136                                                   # loops. Increases the number of cycles requires by convergence by up to 50%,\n",
      "   137                                                   # but greatly enhances stability.\n",
      "   138     49141     600537.0     12.2      5.7          damp_fac = (1. + ((np.abs(del_guess) / np.abs(ant_guess)).sum()) / n_ants) ** -1\n",
      "   139     49141     276346.0      5.6      2.6          ant_guess = ant_guess + (del_guess * damp_fac)\n",
      "   140                                           \n",
      "   141                                                   # Prevent a degenerate case where the phase of the refant becomes 180\n",
      "   142                                                   # instead of zero (i.e. a negative, real number for the gains soln).\n",
      "   143     49141     113796.0      2.3      1.1          if  ant_guess[ref_ant].real < 0:\n",
      "   144                                                       ant_guess *= -1\n",
      "   145                                           \n",
      "   146                                               # Finally, handle the results\n",
      "   147                                           \n",
      "   148                                               # Are there any NaNs, Infs or zeros in the gains soln?\n",
      "   149     16384     347463.0     21.2      3.3      err_check = not (np.all(ant_guess) and np.all(np.isfinite(ant_guess)))\n",
      "   150                                           \n",
      "   151                                               # If we reached the cycle lim or there was an error in the check above,\n",
      "   152                                               # mark solutions as bad.\n",
      "   153     16384      23638.0      1.4      0.2      if (cycle == cycle_lim) or err_check:\n",
      "   154                                                   gain_table = np.zeros(n_ants * 2)\n",
      "   155                                                   gain_covar = np.zeros((n_ants * 2, n_ants * 2))\n",
      "   156                                                   gain_errs = np.zeros(n_ants * 2)\n",
      "   157                                               else:\n",
      "   158     16384      17080.0      1.0      0.2          gain_table = ant_guess\n",
      "   159     16384     435904.0     26.6      4.2          covar_matrix = np.linalg.inv(alpha_matrix)\n",
      "   160     16384     115321.0      7.0      1.1          rchi2_val =  np.dot(y_vec, y_vec) / ((2 * len(vis_data)) - ((2 * n_ants) - 1))\n",
      "   161     16384      55074.0      3.4      0.5          gain_var = np.zeros(2 * n_ants, dtype=float_dtype)\n",
      "   162     16384     243747.0     14.9      2.3          gain_var[guess_mask] = np.diag(covar_matrix) * rchi2_val\n",
      "   163     16384      39531.0      2.4      0.4          gain_var[2 * ref_ant] *= 2\n",
      "   164     16384     190450.0     11.6      1.8          gain_errs = np.sqrt(gain_var.reshape(-1, 2).sum(-1) * 0.5)\n",
      "   165                                           \n",
      "   166     16384      18829.0      1.1      0.2      return gain_table, gain_errs, cycle"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.10.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.2 64-bit (conda)"
  },
  "interpreter": {
   "hash": "a4852ec575df7367bd66f4e41f169ef7c1b82ce08e973ccce0a3fcce5f360bb9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}